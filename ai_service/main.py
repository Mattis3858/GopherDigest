import os
import json
from fastapi import FastAPI, HTTPException
from pydantic import BaseModel, Field
from typing import List
import uvicorn
from dotenv import load_dotenv

from curl_cffi import requests
from bs4 import BeautifulSoup

# LangChain ç›¸é—œ
from langchain_ollama import ChatOllama
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.output_parsers import PydanticOutputParser

load_dotenv()

app = FastAPI()

llm = ChatOllama(model="gemma3:4b", temperature=0)

class ArticleSummary(BaseModel):
    title: str = Field(description="æ–‡ç« çš„æ¨™é¡Œã€‚")
    summary: str = Field(description="æ–‡ç« çš„ç¹é«”ä¸­æ–‡æ‘˜è¦ï¼Œç´„500å­—ï¼Œéœ€åŒ…å«æ ¸å¿ƒæŠ€è¡“èˆ‡çµè«–")
    tags: List[str] = Field(description="3-5 å€‹ç›¸é—œçš„æŠ€è¡“æ¨™ç±¤")

parser = PydanticOutputParser(pydantic_object=ArticleSummary)

def __custom_scraper(url: str) -> str:

    headers = {
        'Accept': 'application/json',
        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
    }
    
    # --- ç­–ç•¥ 1: å˜—è©¦ JSON API ---
    try:
        api_url = f"{url}?format=json"
        response = requests.get(api_url, impersonate="chrome120", headers=headers, timeout=10)
        
        if response.status_code == 200:
            text = response.text
            start_idx = text.find('{')
            if start_idx != -1:
                try:
                    # å˜—è©¦è§£æï¼Œå¤±æ•—æœƒè·³åˆ°ä¸‹æ–¹çš„ except
                    data = json.loads(text[start_idx:])
                    value = data.get("payload", {}).get("value", {})
                    if value:
                        paragraphs = value.get("content", {}).get("bodyModel", {}).get("paragraphs", [])
                        content = "\n".join([p.get("text", "") for p in paragraphs])
                        if len(content) > 100:
                            print("âœ… é€é JSON API æŠ“å–æˆåŠŸ")
                            return content
                except json.JSONDecodeError as je:
                    print(f"ğŸ’¡ JSON æ ¼å¼ç•°å¸¸ ({je})ï¼Œæº–å‚™åˆ‡æ› HTML æ¨¡å¼...")
    except Exception as e:
        print(f"ğŸ’¡ JSON è«‹æ±‚å¤±æ•—: {e}")

    # --- ç­–ç•¥ 2: å˜—è©¦ HTML è§£æ (å‚™æ´) ---
    print(f"âš ï¸ æ­£åœ¨å° {url} åŸ·è¡Œ HTML è§£æå‚™æ´...")
    try:
        html_res = requests.get(url, impersonate="chrome120", timeout=100)
        if html_res.status_code == 200:
            soup = BeautifulSoup(html_res.text, 'html.parser')
            
            # å„ªå…ˆæŠ“å– article æ¨™ç±¤ï¼Œé€™èƒ½éæ¿¾æ‰å¤§éƒ¨åˆ†é›œè³ª
            article = soup.find('article')
            target = article if article else soup
            
            # æŠ“å–å¸¸è¦‹çš„æ–‡ç« å…§å®¹æ¨™ç±¤
            tags = target.find_all(['p', 'h1', 'h2', 'h3', 'h4', 'blockquote', 'li'])
            content = "\n\n".join([t.get_text().strip() for t in tags if t.get_text().strip()])
            
            if len(content) > 100:
                print("âœ… é€é HTML è§£ææˆåŠŸ")
                return content
            else:
                print("âŒ HTML è§£æå…§å®¹éçŸ­")
    except Exception as e:
        print(f"âŒ HTML å‚™æ´æ¨¡å¼ä¹Ÿå¤±æ•—: {e}")
    
    return ""
# --- 3. Prompt è¨­å®š ---
system_prompt = """
# Role
ä½ æ˜¯ä¸€ä½è³‡æ·±çš„æŠ€è¡“å…§å®¹ä¸»ç·¨ï¼Œæ“…é•·å¿«é€Ÿè§£æè¤‡é›œçš„æŠ€è¡“æ–‡ç« ä¸¦æå–æ ¸å¿ƒåƒ¹å€¼ã€‚

# Objective
ä½ çš„ä»»å‹™æ˜¯é–±è®€ä½¿ç”¨è€…æä¾›çš„æ–‡ç« å…§å®¹ï¼Œä¸¦ç”¢å‡ºçµæ§‹åŒ–çš„æ‘˜è¦è³‡è¨Šã€‚

# Constraints
1. **æ¨™é¡Œæº–ç¢ºæ€§**ï¼šå„ªå…ˆä½¿ç”¨æ–‡ç« åŸå§‹æ¨™é¡Œã€‚
2. **èªè¨€è¦æ±‚**ï¼šæ‘˜è¦èˆ‡æ¨™é¡Œå¿…é ˆä½¿ç”¨**ç¹é«”ä¸­æ–‡ (Traditional Chinese, Taiwan)**ã€‚
3. **è¼¸å‡ºæ ¼å¼**ï¼šåªå›å‚³ç¬¦åˆ Schema å®šç¾©çš„ JSONã€‚
4. **å…§å®¹å®Œæ•´æ€§**ï¼šæ‘˜è¦ä¸­éœ€æåŠé—œéµæŠ€è¡“é‚è¼¯ã€‚

{format_instructions}
"""

prompt = ChatPromptTemplate.from_messages([
    ("system", system_prompt),
    ("human", "è«‹é‡å°ä»¥ä¸‹æ–‡ç« å…§å®¹é€²è¡Œæ‘˜è¦èˆ‡æ¨™ç±¤æå–ï¼š\n\n<article_content>\n{content}\n</article_content>"),
]).partial(format_instructions=parser.get_format_instructions())

chain = prompt | llm | parser

# --- 4. API Endpoints ---
class ArticleRequest(BaseModel):
    url: str

@app.post("/summarize", response_model=ArticleSummary)
async def summarize_article(request: ArticleRequest):
    print(f"ğŸš€ é–‹å§‹æŠ“å–æ–‡ç« : {request.url}")
    
    # èª¿ç”¨è‡ªå®šç¾©çˆ¬èŸ²
    final_content = __custom_scraper(request.url)
    
    if not final_content:
        raise HTTPException(status_code=400, detail="ç„¡æ³•æŠ“å–è©²ç¶²å€å…§å®¹ï¼Œå¯èƒ½æ˜¯ç¶²ç«™é˜²è­·å‡ç´šæˆ–ç¶²å€ç„¡æ•ˆ")

    print(f"ğŸ“ æŠ“å–æˆåŠŸï¼Œé•·åº¦ç´„ {len(final_content)} å­—")

    # å…§å®¹æˆªæ–·é‚è¼¯ (è¦– LLM context window èª¿æ•´ï¼ŒGemma 3 å¯è™•ç†è¼ƒé•·å…§å®¹ï¼Œå¯è¨­ 3000-5000)
    if len(final_content) > 5000:
        final_content = final_content[:5000]
        print("âš ï¸ æ–‡ç« éé•·ï¼Œå·²æˆªæ–·è‡³å‰ 5000 å­—")

    try:
        print(f"ğŸ¤– é€å…¥ AI ({llm.model}) è™•ç†ä¸­...")
        return chain.invoke({"content": final_content})
    except Exception as e:
        print(f"âŒ LLM è™•ç†éŒ¯èª¤: {e}")
        raise HTTPException(status_code=500, detail=f"AI è™•ç†å¤±æ•—: {str(e)}")

if __name__ == "__main__":
    uvicorn.run(app, host="0.0.0.0", port=8000)